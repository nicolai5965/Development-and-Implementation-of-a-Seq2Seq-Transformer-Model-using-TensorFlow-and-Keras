{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1wxT13r4GYQgUwat8HZM5eoF9TW7Tx5By",
      "authorship_tag": "ABX9TyNuOBJgEoVPBgrPF5RBX+A5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolai5965/Transformer_scratch_tensorflow/blob/main/Branch_3_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wsYlOd58kKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8617e03-bb42-4143-d88b-11ed27b15e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import re\n",
        "import time\n",
        "\n",
        "from nltk.corpus import words\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "# Mount Google Drive to load the dataset\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zszVsFGO8tua"
      },
      "outputs": [],
      "source": [
        "# Define the file path and load the train and test data\n",
        "filepath = '/content/drive/My Drive/Colab Notebooks/Machine Learning/TensorFlow/GRU/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_mwPutS86lU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(f'{filepath}fake_or_real_news.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Rb_jzt68-Nk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "1f4cd4cb-67b4-4c8f-a168-c63d60454c8b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         id                                              title  \\\n",
              "0      8476                       You Can Smell Hillary’s Fear   \n",
              "1     10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
              "2      3608        Kerry to go to Paris in gesture of sympathy   \n",
              "3     10142  Bernie supporters on Twitter erupt in anger ag...   \n",
              "4       875   The Battle of New York: Why This Primary Matters   \n",
              "...     ...                                                ...   \n",
              "6330   4490  State Department says it can't find emails fro...   \n",
              "6331   8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
              "6332   8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
              "6333   4021  In Ethiopia, Obama seeks progress on peace, se...   \n",
              "6334   4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
              "\n",
              "                                                   text label  \n",
              "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
              "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
              "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
              "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
              "4     It's primary day in New York and front-runners...  REAL  \n",
              "...                                                 ...   ...  \n",
              "6330  The State Department told the Republican Natio...  REAL  \n",
              "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
              "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
              "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
              "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
              "\n",
              "[6335 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-127f8bb1-8c08-40a1-988d-4ad2460db86b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8476</td>\n",
              "      <td>You Can Smell Hillary’s Fear</td>\n",
              "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10294</td>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3608</td>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
              "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10142</td>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>875</td>\n",
              "      <td>The Battle of New York: Why This Primary Matters</td>\n",
              "      <td>It's primary day in New York and front-runners...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6330</th>\n",
              "      <td>4490</td>\n",
              "      <td>State Department says it can't find emails fro...</td>\n",
              "      <td>The State Department told the Republican Natio...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6331</th>\n",
              "      <td>8062</td>\n",
              "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
              "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6332</th>\n",
              "      <td>8622</td>\n",
              "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
              "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6333</th>\n",
              "      <td>4021</td>\n",
              "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
              "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6334</th>\n",
              "      <td>4330</td>\n",
              "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
              "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6335 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-127f8bb1-8c08-40a1-988d-4ad2460db86b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-127f8bb1-8c08-40a1-988d-4ad2460db86b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-127f8bb1-8c08-40a1-988d-4ad2460db86b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextPreprocessor:\n",
        "    def __init__(self, remove_list, fraction, column_name):\n",
        "        self.remove_list = remove_list\n",
        "        self.fraction = fraction\n",
        "        self.column_name = column_name\n",
        "\n",
        "    def preprocess(self, df):\n",
        "        df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
        "        num_samples = int(len(df_shuffled) * self.fraction)\n",
        "        df_subset = df_shuffled[:num_samples].copy()\n",
        "\n",
        "        df_subset[self.column_name] = df_subset[self.column_name].apply(self._remove_strings)\n",
        "        return df_subset[self.column_name].values\n",
        "\n",
        "    def _remove_strings(self, text):\n",
        "        for string in self.remove_list:\n",
        "            text = text.replace(string, ' ')\n",
        "        text = re.sub(r'http\\S+|www.\\S+', '', text, flags=re.MULTILINE)\n",
        "        text = re.sub(r'\\(@\\w+\\)', '', text)\n",
        "        return text.lower()\n",
        "\n",
        "\n",
        "class TextTokenizer:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = Tokenizer()\n",
        "\n",
        "    def fit(self, texts):\n",
        "        self.tokenizer.fit_on_texts(texts)\n",
        "        self.tokenizer.word_index['<SOS>'] = len(self.tokenizer.word_index) + 1\n",
        "        self.tokenizer.word_index['<EOS>'] = len(self.tokenizer.word_index) + 1\n",
        "\n",
        "    def tokenize(self, texts):\n",
        "        return [self._custom_tokenize_text(t) for t in texts]\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        return self.tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "    def _custom_tokenize_text(self, text):\n",
        "        return re.findall(r'\\b\\w+\\b|[' + string.punctuation + ']', text)\n",
        "\n",
        "    @property\n",
        "    def word_index(self):\n",
        "        return self.tokenizer.word_index\n",
        "\n",
        "    @property\n",
        "    def index_word(self):\n",
        "        return self.tokenizer.index_word\n",
        "\n",
        "\n",
        "\n",
        "class PadToFixed:\n",
        "    def __init__(self, max_sequence_len):\n",
        "        self.max_sequence_len = max_sequence_len\n",
        "\n",
        "    def fit_transform(self, encoder_sequences, decoder_sequences, decoder_labels):\n",
        "        return self._pad_to_fixed(encoder_sequences, decoder_sequences, decoder_labels)\n",
        "\n",
        "    def _pad_to_fixed(self, encoder_sequences, decoder_sequences, decoder_labels):\n",
        "        encoder_sequences = tf.keras.preprocessing.sequence.pad_sequences(encoder_sequences, padding='post', maxlen=self.max_sequence_len)\n",
        "        decoder_sequences = tf.keras.preprocessing.sequence.pad_sequences(decoder_sequences, padding='post', maxlen=self.max_sequence_len)\n",
        "        decoder_labels = tf.keras.preprocessing.sequence.pad_sequences(decoder_labels, padding='post', maxlen=self.max_sequence_len)\n",
        "        return encoder_sequences, decoder_sequences, decoder_labels\n",
        "\n",
        "\n",
        "def add_SOS_EOS_tokens(sequences, tokenizer):\n",
        "    encoder_sequences = [[tokenizer.word_index['<SOS>']] + seq + [tokenizer.word_index['<EOS>']] for seq in sequences]\n",
        "    decoder_sequences = [[tokenizer.word_index['<SOS>']] + seq[1:] for seq in sequences]\n",
        "    decoder_labels = [seq[1:] + [tokenizer.word_index['<EOS>']] for seq in sequences]\n",
        "    return encoder_sequences, decoder_sequences, decoder_labels\n",
        "\n"
      ],
      "metadata": {
        "id": "4XXwNJrkKtzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data_information(train_encoder_inputs, train_decoder_inputs, train_decoder_labels,\n",
        "                              val_encoder_inputs, val_decoder_inputs, val_decoder_labels):\n",
        "    # Create a DataFrame for sequence shapes information\n",
        "    data_sequence_shapes = {\n",
        "        'Train Encoder Input Shape': [],\n",
        "        'Train Decoder Input Shape': [],\n",
        "        'Train Decoder Label Shape': [],\n",
        "        'Val Encoder Input Shape': [],\n",
        "        'Val Decoder Input Shape': [],\n",
        "        'Val Decoder Label Shape': [],\n",
        "    }\n",
        "\n",
        "    # Add the sequence shapes to the DataFrame\n",
        "    data_sequence_shapes['Train Encoder Input Shape'].append(train_encoder_inputs.shape)\n",
        "    data_sequence_shapes['Train Decoder Input Shape'].append(train_decoder_inputs.shape)\n",
        "    data_sequence_shapes['Train Decoder Label Shape'].append(train_decoder_labels.shape)\n",
        "    data_sequence_shapes['Val Encoder Input Shape'].append(val_encoder_inputs.shape)\n",
        "    data_sequence_shapes['Val Decoder Input Shape'].append(val_decoder_inputs.shape)\n",
        "    data_sequence_shapes['Val Decoder Label Shape'].append(val_decoder_labels.shape)\n",
        "\n",
        "    df_sequence_shapes = pd.DataFrame(data_sequence_shapes)\n",
        "\n",
        "    # Create a DataFrame for dataset information\n",
        "    data_dataset = {\n",
        "        'Dataset': ['Train Encoder Input', 'Train Decoder Input', 'Train Decoder Label', 'Val Encoder Input', 'Val Decoder Input', 'Val Decoder Label'],\n",
        "        'Total Tokens': [len(train_encoder_inputs), len(train_decoder_inputs), len(train_decoder_labels), len(val_encoder_inputs), len(val_decoder_inputs), len(val_decoder_labels)],\n",
        "        'Total Parameters': [train_encoder_inputs.size, train_decoder_inputs.size, train_decoder_labels.size, val_encoder_inputs.size, val_decoder_inputs.size, val_decoder_labels.size]\n",
        "    }\n",
        "\n",
        "    df_dataset = pd.DataFrame(data_dataset)\n",
        "\n",
        "    # Display the sequence shapes DataFrame\n",
        "    print(\"Sequence Shapes:\")\n",
        "    display(df_sequence_shapes)\n",
        "\n",
        "    # Display the dataset information DataFrame\n",
        "    print(\"Dataset Information:\")\n",
        "    display(df_dataset)\n"
      ],
      "metadata": {
        "id": "BLr9AiyAHK9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreprocessor:\n",
        "    def __init__(self, config, verbose_1=True, verbose_2=True):\n",
        "        self.config = config\n",
        "        self.verbose_1 = verbose_1\n",
        "        self.verbose_2 = verbose_2\n",
        "\n",
        "    def preprocess(self):\n",
        "        preprocessor = TextPreprocessor(\n",
        "            remove_list=self.config['remove_list'],\n",
        "            fraction=self.config['data_proportion'],\n",
        "            column_name=self.config['column_name']\n",
        "        )\n",
        "\n",
        "        text = preprocessor.preprocess(self.config['dataframe'])\n",
        "        text = [sent_tokenize(t) for t in text]\n",
        "        text = [sent for article in text for sent in article]\n",
        "\n",
        "        train_text, val_text = train_test_split(text, test_size=self.config['val_split_size'], random_state=42)\n",
        "\n",
        "        tokenizer = TextTokenizer()\n",
        "        tokenizer.fit(train_text)\n",
        "\n",
        "        train_tokens = tokenizer.tokenize(train_text)\n",
        "        val_tokens = tokenizer.tokenize(val_text)\n",
        "\n",
        "        total_words = sum([len(t) for t in train_tokens])\n",
        "\n",
        "        encoder_sequences_train, decoder_sequences_train, decoder_labels_train = add_SOS_EOS_tokens(tokenizer.texts_to_sequences(train_tokens), tokenizer)\n",
        "        encoder_sequences_val, decoder_sequences_val, decoder_labels_val = add_SOS_EOS_tokens(tokenizer.texts_to_sequences(val_tokens), tokenizer)\n",
        "\n",
        "        pad_to_fixed = PadToFixed(max_sequence_len=self.config['max_sequence_len'])\n",
        "        encoder_input_train, decoder_input_train, decoder_target_train = pad_to_fixed.fit_transform(encoder_sequences_train, decoder_sequences_train, decoder_labels_train)\n",
        "        encoder_input_val, decoder_input_val, decoder_target_val = pad_to_fixed.fit_transform(encoder_sequences_val, decoder_sequences_val, decoder_labels_val)\n",
        "\n",
        "        if self.verbose_1:\n",
        "            generate_data_information(encoder_input_train, decoder_input_train, decoder_target_train,\n",
        "                                      encoder_input_val, decoder_input_val, decoder_target_val)\n",
        "\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((encoder_input_train, decoder_input_train, decoder_target_train))\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices((encoder_input_val, decoder_input_val, decoder_target_val))\n",
        "\n",
        "        train_dataset = train_dataset.shuffle(self.config['BUFFER_SIZE']).batch(self.config['BATCH_SIZE'], drop_remainder=False)\n",
        "        val_dataset = val_dataset.batch(self.config['BATCH_SIZE'], drop_remainder=False)  # Note: No need to shuffle the validation data\n",
        "\n",
        "        return train_dataset, val_dataset, len(tokenizer.word_index) + 1, tokenizer\n",
        "\n",
        "    def get_max_sequence_lengths(self):\n",
        "        return self.config['max_sequence_len'], self.config['max_sequence_len']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hVTQgLeKWPE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyEmbeddingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, d_model, verbose=False, name=\"my_embedding_layer\", **kwargs):\n",
        "        super(MyEmbeddingLayer, self).__init__(name=name, **kwargs)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        self.verbose = verbose\n",
        "        # Initialize the embedding matrix randomly\n",
        "        self.embedding_matrix = self.add_weight(\n",
        "            shape=[vocab_size, d_model],\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embeddings = tf.nn.embedding_lookup(self.embedding_matrix, inputs)\n",
        "        if self.verbose:\n",
        "            print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "        return embeddings\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'd_model': self.d_model,\n",
        "            'verbose': self.verbose\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n"
      ],
      "metadata": {
        "id": "AzpUBfoP2wS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, position, d_model, name=\"positional_encoding\", **kwargs):\n",
        "        super(PositionalEncoding, self).__init__(name=name, **kwargs)\n",
        "        self.position = position\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.pos_encoding = self.calculate_positional_encoding()\n",
        "\n",
        "    def calculate_positional_encoding(self):\n",
        "        angle_rads = self.get_angles(\n",
        "            np.arange(self.position)[:, np.newaxis],\n",
        "            np.arange(self.d_model)[np.newaxis, :],\n",
        "            self.d_model\n",
        "        )\n",
        "\n",
        "        # apply sin to even indices in the array; 2i\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "        # apply cos to odd indices in the array; 2i+1\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = angle_rads[np.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_angles(pos, i, d_model):\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "        return pos * angle_rates\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'position': self.position,\n",
        "            'd_model': self.d_model\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n"
      ],
      "metadata": {
        "id": "1x_3OcFiz5IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.keras.layers.Lambda(lambda x: tf.matmul(x[0], x[1], transpose_b=True),\n",
        "                                       name=\"matmul_qk\")([q, k])\n",
        "\n",
        "    depth = tf.keras.layers.Lambda(lambda x: tf.cast(tf.shape(x)[-1], tf.float32),\n",
        "                                   name=\"depth\")(k)\n",
        "    logits = tf.keras.layers.Lambda(lambda x: x[0] / tf.math.sqrt(x[1]),\n",
        "                                    name=\"logits\")([matmul_qk, depth])\n",
        "\n",
        "    if mask is not None:\n",
        "        logits = tf.keras.layers.Lambda(lambda x: x[0] + (x[1] * -1e9),\n",
        "                                        name=\"logits_masked\")([logits, mask])\n",
        "\n",
        "    attention_weights = tf.keras.layers.Lambda(lambda x: tf.nn.softmax(x, axis=-1),\n",
        "                                               name=\"attention_weights\")(logits)\n",
        "    return tf.keras.layers.Lambda(lambda x: tf.matmul(x[0], x[1]),\n",
        "                                  name=\"output\")([attention_weights, v]), attention_weights\n",
        "\n",
        "\n",
        "def create_padding_mask(seq, identifier):\n",
        "    seq = tf.keras.layers.Lambda(lambda x: tf.cast(tf.math.equal(x, 0), tf.float32),\n",
        "                                 name=f\"padding_mask_{identifier}\")(seq)\n",
        "    return tf.keras.layers.Lambda(lambda x: x[:, tf.newaxis, tf.newaxis, :],\n",
        "                                  name=f\"padding_mask_expanded_{identifier}\")(seq)\n",
        "\n",
        "\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    ones_matrix = tf.keras.layers.Lambda(lambda x: tf.ones((x, x)),\n",
        "                                         name=\"look_ahead_mask_ones_matrix\")(size)\n",
        "    mask = tf.keras.layers.Lambda(lambda x: 1 - tf.linalg.band_part(x, -1, 0),\n",
        "                                  name=\"look_ahead_mask\")(ones_matrix)\n",
        "    return mask\n"
      ],
      "metadata": {
        "id": "YKjyPaiP6AX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\", **kwargs):\n",
        "        super(MultiHeadAttention, self).__init__(name=name, **kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0  # Ensure d_model is divisible evenly by num_heads\n",
        "\n",
        "        self.depth = d_model // self.num_heads  # Calculate depth for each head\n",
        "\n",
        "        self.query_lin = tf.keras.layers.Dense(d_model, name=name+\"_query_lin\")  # Linear transformation layer for queries\n",
        "        self.key_lin = tf.keras.layers.Dense(d_model, name=name+\"_key_lin\")  # Linear transformation layer for keys\n",
        "        self.value_lin = tf.keras.layers.Dense(d_model, name=name+\"_value_lin\")  # Linear transformation layer for values\n",
        "\n",
        "        self.final_lin = tf.keras.layers.Dense(d_model, name=name+\"_final_lin\")  # Linear transformation layer for final output\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))  # Reshape input tensor to split the last dimension\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])  # Transpose the tensor dimensions\n",
        "\n",
        "    def call(self, v, k, q, mask=None):\n",
        "        batch_size = tf.shape(q)[0]  # Get the batch size\n",
        "\n",
        "        W_q = self.query_lin(q)  # Linear transformation for queries\n",
        "        W_k = self.key_lin(k)  # Linear transformation for keys\n",
        "        W_v = self.value_lin(v)  # Linear transformation for values\n",
        "\n",
        "        q_split = self.split_heads(W_q, batch_size)  # Split queries into multiple heads\n",
        "        k_split = self.split_heads(W_k, batch_size)  # Split keys into multiple heads\n",
        "        v_split = self.split_heads(W_v, batch_size)  # Split values into multiple heads\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q_split, k_split, v_split, mask)  # Calculate scaled dot product attention\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # Transpose attention output\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))  # Reshape attention output\n",
        "\n",
        "        output = self.final_lin(concat_attention)  # Linear transformation for final output\n",
        "\n",
        "        return output, attention_weights#, W_q, W_k, W_v, q_split, k_split, v_split\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(MultiHeadAttention, self).get_config()\n",
        "        config.update({\n",
        "            'd_model': self.d_model,\n",
        "            'num_heads': self.num_heads,\n",
        "            'name': self.name,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)"
      ],
      "metadata": {
        "id": "QWVRtTmYwy4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PointWiseFeedForwardNetwork(tf.keras.Model):\n",
        "    def __init__(self, d_model, dff, identifier, **kwargs):\n",
        "        super(PointWiseFeedForwardNetwork, self).__init__(**kwargs)\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.dff = dff\n",
        "        self.identifier = identifier\n",
        "\n",
        "        self.layer1 = tf.keras.layers.Dense(dff, activation='relu', name=f'feed_forward_relu_{identifier}')\n",
        "        self.layer2 = tf.keras.layers.Dense(d_model, name=f'feed_forward_output_{identifier}')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.layer1(x)\n",
        "        return self.layer2(x)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'd_model': self.d_model,\n",
        "            'dff': self.dff,\n",
        "            'identifier': self.identifier,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n"
      ],
      "metadata": {
        "id": "GCFmC7K5Aclj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NormAndAdd(tf.keras.layers.Layer):\n",
        "    def __init__(self, layernorm, **kwargs):\n",
        "        super(NormAndAdd, self).__init__(**kwargs)\n",
        "        self.layernorm = layernorm\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.layernorm(inputs[0] + inputs[1])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(NormAndAdd, self).get_config()\n",
        "        config.update({\n",
        "            'layernorm': {\n",
        "                'class_name': self.layernorm.__class__.__name__,\n",
        "                'config': self.layernorm.get_config(),\n",
        "            },\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        layernorm_config = config.pop('layernorm')\n",
        "        layernorm_class = tf.keras.layers.deserialize(layernorm_config)\n",
        "        return cls(layernorm=layernorm_class, **config)"
      ],
      "metadata": {
        "id": "KEmWG5UAtx7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1, name='encoder_layer',\n",
        "                 mha=None, ffn=None, norm_and_add1=None, norm_and_add2=None, **kwargs):\n",
        "        super(EncoderLayer, self).__init__(name=name, **kwargs)\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.dff = dff\n",
        "        self.rate = rate\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads, name='MHA_encoder') if mha is None else mha\n",
        "        self.ffn = PointWiseFeedForwardNetwork(d_model, dff, 'encoder') if ffn is None else ffn\n",
        "\n",
        "        self.norm_and_add1 = NormAndAdd(tf.keras.layers.LayerNormalization(epsilon=1e-6), name='encoder_NaA_1') if norm_and_add1 is None else norm_and_add1\n",
        "        self.norm_and_add2 = NormAndAdd(tf.keras.layers.LayerNormalization(epsilon=1e-6), name='encoder_NaA_2') if norm_and_add2 is None else norm_and_add2\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, padding_mask):\n",
        "        attn_output, attn_weights = self.mha(x, x, x, padding_mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.norm_and_add1([x, attn_output])  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.norm_and_add2([out1, ffn_output])  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'd_model': self.d_model,\n",
        "            'num_heads': self.num_heads,\n",
        "            'dff': self.dff,\n",
        "            'rate': self.rate,\n",
        "            'name': self.name,\n",
        "            'mha': {\n",
        "                'class_name': self.mha.__class__.__name__,\n",
        "                'config': self.mha.get_config(),\n",
        "            },\n",
        "            'ffn': {\n",
        "                'class_name': self.ffn.__class__.__name__,\n",
        "                'config': self.ffn.get_config(),\n",
        "            },\n",
        "            'norm_and_add1': {\n",
        "                'class_name': self.norm_and_add1.__class__.__name__,\n",
        "                'config': self.norm_and_add1.get_config(),\n",
        "            },\n",
        "            'norm_and_add2': {\n",
        "                'class_name': self.norm_and_add2.__class__.__name__,\n",
        "                'config': self.norm_and_add2.get_config(),\n",
        "            },\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        config['mha'] = deserialize_layer(config['mha'])\n",
        "        config['ffn'] = deserialize_layer(config['ffn'])\n",
        "        config['norm_and_add1'] = deserialize_layer(config['norm_and_add1'])\n",
        "        config['norm_and_add2'] = deserialize_layer(config['norm_and_add2'])\n",
        "        return cls(**config)"
      ],
      "metadata": {
        "id": "2x8NtwULAarj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1, name='decoder_layer', mha1=None, mha2=None, ffn=None, norm_and_add1=None, norm_and_add2=None, norm_and_add3=None, **kwargs):\n",
        "        super(DecoderLayer, self).__init__(name=name, **kwargs)\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.dff = dff\n",
        "        self.rate = rate\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads, name='MHA_decoder_1') if mha1 is None else mha1\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads, name='MHA_decoder_2') if mha2 is None else mha2\n",
        "\n",
        "        self.ffn = PointWiseFeedForwardNetwork(d_model, dff, 'decoder') if ffn is None else ffn  # Use PointWiseFeedForwardNetwork class\n",
        "\n",
        "        self.norm_and_add1 = NormAndAdd(tf.keras.layers.LayerNormalization(epsilon=1e-6), name='decoder_NaA_1') if norm_and_add1 is None else norm_and_add1\n",
        "        self.norm_and_add2 = NormAndAdd(tf.keras.layers.LayerNormalization(epsilon=1e-6), name='decoder_NaA_2') if norm_and_add2 is None else norm_and_add2\n",
        "        self.norm_and_add3 = NormAndAdd(tf.keras.layers.LayerNormalization(epsilon=1e-6), name='decoder_NaA_3') if norm_and_add3 is None else norm_and_add3\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, dec_input, enc_output, training, look_ahead_mask, dec_padding_mask, enc_padding_mask):\n",
        "        combined_mask = tf.keras.layers.Lambda(lambda x: tf.maximum(x[0], x[1]), name=\"mask_combiner\")([look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "        attn1, attn_weights_block1 = self.mha1(dec_input, dec_input, dec_input, combined_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.norm_and_add1([attn1, dec_input])\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, enc_padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.norm_and_add2([attn2, out1])  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.norm_and_add3([ffn_output, out2])  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'd_model': self.d_model,\n",
        "            'num_heads': self.num_heads,\n",
        "            'dff': self.dff,\n",
        "            'rate': self.rate,\n",
        "            'name': self.name,\n",
        "            'mha1': {\n",
        "                'class_name': self.mha1.__class__.__name__,\n",
        "                'config': self.mha1.get_config(),\n",
        "            },\n",
        "            'mha2': {\n",
        "                'class_name': self.mha2.__class__.__name__,\n",
        "                'config': self.mha2.get_config(),\n",
        "            },\n",
        "            'ffn': {\n",
        "                'class_name': self.ffn.__class__.__name__,\n",
        "                'config': self.ffn.get_config(),\n",
        "            },\n",
        "            'norm_and_add1': {\n",
        "                'class_name': self.norm_and_add1.__class__.__name__,\n",
        "                'config': self.norm_and_add1.get_config(),\n",
        "            },\n",
        "            'norm_and_add2': {\n",
        "                'class_name': self.norm_and_add2.__class__.__name__,\n",
        "                'config': self.norm_and_add2.get_config(),\n",
        "            },\n",
        "            'norm_and_add3': {\n",
        "                'class_name': self.norm_and_add3.__class__.__name__,\n",
        "                'config': self.norm_and_add3.get_config(),\n",
        "            },\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        config['mha1'] = deserialize_layer(config['mha1'])\n",
        "        config['mha2'] = deserialize_layer(config['mha2'])\n",
        "        config['ffn'] = deserialize_layer(config['ffn'])\n",
        "        config['norm_and_add1'] = deserialize_layer(config['norm_and_add1'])\n",
        "        config['norm_and_add2'] = deserialize_layer(config['norm_and_add2'])\n",
        "        config['norm_and_add3'] = deserialize_layer(config['norm_and_add3'])\n",
        "        return cls(**config)\n"
      ],
      "metadata": {
        "id": "5v17z68-F0Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import deserialize as deserialize_layer\n"
      ],
      "metadata": {
        "id": "AkfjfxZe7AkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deserialize_layer(layer_dict):\n",
        "    from tensorflow.keras.layers import deserialize as deserialize_layer\n",
        "    return deserialize_layer(layer_dict)\n"
      ],
      "metadata": {
        "id": "uGbjh1yI-Ojv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoder and Decoder blocks**"
      ],
      "metadata": {
        "id": "UFbqHHZ2y0Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, max_position, rate=0.1, name='Encoder_Block',\n",
        "                 embedding_layer=None, pos_encoding_layer=None, encoder_layers=None, **kwargs):\n",
        "        super(Encoder, self).__init__(name=name, **kwargs)\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.num_heads = num_heads\n",
        "        self.dff = dff\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "        self.max_position = max_position\n",
        "        self.rate = rate\n",
        "\n",
        "        if embedding_layer is None:\n",
        "            self.embedding = MyEmbeddingLayer(input_vocab_size, d_model, name='encoder_embedding')\n",
        "        else:\n",
        "            self.embedding = embedding_layer\n",
        "\n",
        "        if pos_encoding_layer is None:\n",
        "            self.pos_encoding = PositionalEncoding(max_position, d_model, name='encoder_encoding')\n",
        "        else:\n",
        "            self.pos_encoding = pos_encoding_layer\n",
        "\n",
        "        if encoder_layers is None:\n",
        "            self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate, name=f\"encoder_layer_{i+1}\")\n",
        "                               for i in range(num_layers)]\n",
        "        else:\n",
        "            self.enc_layers = encoder_layers\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        #seq_len = tf.shape(x)[1]\n",
        "        seq_len = tf.keras.layers.Lambda(lambda x: tf.shape(x)[1], name=\"encoder_sequence_length\")(x)\n",
        "\n",
        "        x_emb = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "        x_pos_enc = self.pos_encoding(x_emb)\n",
        "        x_pos_enc_dropout = self.dropout(x_pos_enc, training=training)\n",
        "\n",
        "        x_enc_output = x_pos_enc_dropout\n",
        "        for i in range(self.num_layers):\n",
        "            x_enc_output = self.enc_layers[i](x_enc_output, training, mask)\n",
        "\n",
        "        return x_enc_output  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Encoder, self).get_config()\n",
        "        config.update({\n",
        "            'num_layers': self.num_layers,\n",
        "            'd_model': self.d_model,\n",
        "            'num_heads': self.num_heads,\n",
        "            'dff': self.dff,\n",
        "            'input_vocab_size': self.input_vocab_size,\n",
        "            'max_position': self.max_position,\n",
        "            'rate': self.rate,\n",
        "            'name': self.name,\n",
        "            'embedding_layer': {\n",
        "                'class_name': self.embedding.__class__.__name__,\n",
        "                'config': self.embedding.get_config(),\n",
        "            },\n",
        "            'pos_encoding_layer': {\n",
        "                'class_name': self.pos_encoding.__class__.__name__,\n",
        "                'config': self.pos_encoding.get_config(),\n",
        "            },\n",
        "            'encoder_layers': [\n",
        "                {\n",
        "                    'class_name': layer.__class__.__name__,\n",
        "                    'config': layer.get_config(),\n",
        "                }\n",
        "                for layer in self.enc_layers\n",
        "            ],\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        config['embedding_layer'] = deserialize_layer(config['embedding_layer'])\n",
        "        config['pos_encoding_layer'] = deserialize_layer(config['pos_encoding_layer'])\n",
        "        config['encoder_layers'] = [deserialize_layer(layer_config) for layer_config in config['encoder_layers']]\n",
        "        return cls(**config)\n"
      ],
      "metadata": {
        "id": "Lx7yDvHBy9oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, max_position, rate=0.1, name='Decoder_Block',\n",
        "                 embedding=None, pos_encoding=None, dec_layers=None, dropout=None, **kwargs):\n",
        "        super(Decoder, self).__init__(name=name, **kwargs)\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.num_heads = num_heads\n",
        "        self.dff = dff\n",
        "        self.target_vocab_size = target_vocab_size\n",
        "        self.max_position = max_position\n",
        "        self.rate = rate\n",
        "\n",
        "        if embedding is None:\n",
        "            self.embedding = MyEmbeddingLayer(target_vocab_size, d_model, name='decoder_embedding')\n",
        "        else:\n",
        "            self.embedding = embedding\n",
        "\n",
        "        if pos_encoding is None:\n",
        "            self.pos_encoding = PositionalEncoding(max_position, d_model, name='decoder_encoding')\n",
        "        else:\n",
        "            self.pos_encoding = pos_encoding\n",
        "\n",
        "        if dec_layers is None:\n",
        "            self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate, name=f\"decoder_layer_{i+1}\")\n",
        "                               for i in range(num_layers)]\n",
        "        else:\n",
        "            self.dec_layers = dec_layers\n",
        "\n",
        "        if dropout is None:\n",
        "            self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        else:\n",
        "            self.dropout = dropout\n",
        "\n",
        "    def call(self, dec_input, enc_output, training, look_ahead_mask, dec_padding_mask, enc_padding_mask):\n",
        "        seq_len = tf.keras.layers.Lambda(lambda x: tf.shape(x)[1], name=\"decoder_sequence_length\")(dec_input)\n",
        "\n",
        "        dec_input_emb = self.embedding(dec_input)  # (batch_size, target_seq_len, d_model)\n",
        "        dec_input_pos_enc = self.pos_encoding(dec_input_emb)\n",
        "        dec_input_pos_enc_dropout = self.dropout(dec_input_pos_enc, training=training)\n",
        "        dec_output = dec_input_pos_enc_dropout\n",
        "\n",
        "        attention_weights = {}\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            dec_output, attn_weights_block1, attn_weights_block2 = self.dec_layers[i](dec_output, enc_output, training, look_ahead_mask, dec_padding_mask, enc_padding_mask)\n",
        "\n",
        "            attention_weights[f'decoder_layer{i+1}_block1'] = attn_weights_block1\n",
        "            attention_weights[f'decoder_layer{i+1}_block2'] = attn_weights_block2\n",
        "\n",
        "        return dec_output  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Decoder, self).get_config()\n",
        "        config.update({\n",
        "            'num_layers': self.num_layers,\n",
        "            'd_model': self.d_model,\n",
        "            'num_heads': self.num_heads,\n",
        "            'dff': self.dff,\n",
        "            'target_vocab_size': self.target_vocab_size,\n",
        "            'max_position': self.max_position,\n",
        "            'rate': self.rate,\n",
        "            'name': self.name,\n",
        "            'embedding': {\n",
        "                'class_name': self.embedding.__class__.__name__,\n",
        "                'config': self.embedding.get_config(),\n",
        "            },\n",
        "            'pos_encoding': {\n",
        "                'class_name': self.pos_encoding.__class__.__name__,\n",
        "                'config': self.pos_encoding.get_config(),\n",
        "            },\n",
        "            'dec_layers': [{\n",
        "                'class_name': layer.__class__.__name__,\n",
        "                'config': layer.get_config(),\n",
        "            } for layer in self.dec_layers],\n",
        "            'dropout': {\n",
        "                'class_name': self.dropout.__class__.__name__,\n",
        "                'config': self.dropout.get_config(),\n",
        "            },\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        config['embedding'] = deserialize_layer(config['embedding'])\n",
        "        config['pos_encoding'] = deserialize_layer(config['pos_encoding'])\n",
        "        config['dec_layers'] = [deserialize_layer(layer_config) for layer_config in config['dec_layers']]\n",
        "        config['dropout'] = deserialize_layer(config['dropout'])\n",
        "        return cls(**config)"
      ],
      "metadata": {
        "id": "ZiQbZY5jpvPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, enc_num_layers, dec_num_layers, d_model,\n",
        "                 enc_num_heads, dec_num_heads, enc_dff, dec_dff,\n",
        "                 input_vocab_size, target_vocab_size, pe_input, pe_target,\n",
        "                 enc_rate=0.1, dec_rate=0.1,\n",
        "                 verbose=False, name='Transformer_Block', encoder=None, decoder=None, **kwargs):\n",
        "        super(Transformer, self).__init__(name=name, **kwargs)\n",
        "        self.verbose = verbose\n",
        "        self.call_count = 0\n",
        "        self.enc_num_layers = enc_num_layers\n",
        "        self.dec_num_layers = dec_num_layers\n",
        "        self.d_model = d_model\n",
        "        self.enc_num_heads = enc_num_heads\n",
        "        self.dec_num_heads = dec_num_heads\n",
        "        self.enc_dff = enc_dff\n",
        "        self.dec_dff = dec_dff\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "        self.target_vocab_size = target_vocab_size\n",
        "        self.pe_input = pe_input\n",
        "        self.pe_target = pe_target\n",
        "        self.enc_rate = enc_rate\n",
        "        self.dec_rate = dec_rate\n",
        "\n",
        "        if encoder is None:\n",
        "            self.encoder = Encoder(enc_num_layers, d_model, enc_num_heads, enc_dff,\n",
        "                                   input_vocab_size, pe_input, enc_rate, name='Encoder')\n",
        "        else:\n",
        "            self.encoder = encoder\n",
        "\n",
        "        if decoder is None:\n",
        "            self.decoder = Decoder(dec_num_layers, d_model, dec_num_heads, dec_dff,\n",
        "                                   target_vocab_size, pe_target, dec_rate, name='Decoder')\n",
        "        else:\n",
        "            self.decoder = decoder\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size, dtype='float32', name='transformer_final_layer')\n",
        "\n",
        "\n",
        "    def call(self, inp, tar, training, enc_padding_mask,\n",
        "            look_ahead_mask, dec_padding_mask):\n",
        "        self.call_count += 1\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "        if self.verbose and self.call_count == 1:\n",
        "            print(f\"Encoder output shape: {enc_output.shape}\")\n",
        "\n",
        "        dec_output = self.decoder(\n",
        "            tar, enc_output, training, look_ahead_mask, dec_padding_mask, enc_padding_mask)\n",
        "        if self.verbose and self.call_count == 1:\n",
        "            print(f\"Decoder output shape: {dec_output.shape}\")\n",
        "\n",
        "        final_linear_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "        if self.verbose and self.call_count == 1:\n",
        "            print(f\"Final linear output shape: {final_linear_output.shape}\")\n",
        "\n",
        "        return final_linear_output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Transformer, self).get_config()\n",
        "        config.update({\n",
        "            'enc_num_layers': self.enc_num_layers,\n",
        "            'dec_num_layers': self.dec_num_layers,\n",
        "            'd_model': self.d_model,\n",
        "            'enc_num_heads': self.enc_num_heads,\n",
        "            'dec_num_heads': self.dec_num_heads,\n",
        "            'enc_dff': self.enc_dff,\n",
        "            'dec_dff': self.dec_dff,\n",
        "            'input_vocab_size': self.input_vocab_size,\n",
        "            'target_vocab_size': self.target_vocab_size,\n",
        "            'pe_input': self.pe_input,\n",
        "            'pe_target': self.pe_target,\n",
        "            'enc_rate': self.enc_rate,\n",
        "            'dec_rate': self.dec_rate,\n",
        "            'verbose': self.verbose,\n",
        "            'name': self.name,\n",
        "            'encoder': {\n",
        "                'class_name': self.encoder.__class__.__name__,\n",
        "                'config': self.encoder.get_config(),\n",
        "            },\n",
        "            'decoder': {\n",
        "                'class_name': self.decoder.__class__.__name__,\n",
        "                'config': self.decoder.get_config(),\n",
        "            },\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        config['encoder'] = deserialize_layer(config['encoder'])\n",
        "        config['decoder'] = deserialize_layer(config['decoder'])\n",
        "        return cls(**config)"
      ],
      "metadata": {
        "id": "bRl-QsmWz78-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LossFunction:\n",
        "    def __init__(self):\n",
        "        self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "    def compute(self, real, pred):\n",
        "        mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "        loss_ = self.loss_object(real, pred)\n",
        "\n",
        "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "        loss_ *= mask\n",
        "\n",
        "        return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"d_model\": float(self.d_model.numpy()), \"warmup_steps\": float(self.warmup_steps.numpy())}\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)"
      ],
      "metadata": {
        "id": "XymhXY-Ec_xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deserialize_layer(layer_config):\n",
        "    \"\"\"Creates a layer from its config\"\"\"\n",
        "    # This line might need to be customized depending on your project structure\n",
        "    from tensorflow.keras import layers\n",
        "\n",
        "    # Get the class of the layer from tf.keras.layers\n",
        "    LayerClass = getattr(layers, layer_config['class_name'])\n",
        "\n",
        "    # Create a new instance of the layer\n",
        "    layer = LayerClass.from_config(layer_config['config'])\n",
        "\n",
        "    return layer\n"
      ],
      "metadata": {
        "id": "1f-YMgxz4bwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ModelCreator:\n",
        "    def __init__(self, transformer, config, optimizer, loss_function):\n",
        "        self.transformer = transformer\n",
        "        self.config = config\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_function = loss_function\n",
        "\n",
        "    def create_and_compile(self):\n",
        "        # Define input and output placeholders\n",
        "        input_shape = (None,)  # Variable-length sequence\n",
        "        target_shape = (None,)  # Variable-length sequence\n",
        "\n",
        "        enc_inputs = tf.keras.Input(shape=input_shape, dtype=tf.int32, name='encoder_input')\n",
        "        dec_inputs = tf.keras.Input(shape=input_shape, dtype=tf.int32, name='decoder_input')\n",
        "        dec_targets = tf.keras.Input(shape=target_shape, dtype=tf.int32, name='decoder_targets')\n",
        "\n",
        "        # Create masks\n",
        "        enc_padding_mask = create_padding_mask(enc_inputs, 'encoder')\n",
        "        dec_padding_mask = create_padding_mask(dec_inputs, 'decoder')\n",
        "        dec_seq_len = tf.keras.layers.Lambda(lambda x: tf.shape(x)[1], name=\"decoder_lam_shape\")(dec_inputs)\n",
        "        #look_ahead_mask = create_look_ahead_mask(tf.shape(dec_inputs)[1])\n",
        "        look_ahead_mask = create_look_ahead_mask(dec_seq_len)\n",
        "\n",
        "\n",
        "        # Run the model\n",
        "        outputs = self.transformer(enc_inputs, dec_inputs, training=True,\n",
        "                                         enc_padding_mask=enc_padding_mask,\n",
        "                                         look_ahead_mask=look_ahead_mask,\n",
        "                                         dec_padding_mask=dec_padding_mask)\n",
        "\n",
        "        # Define the model\n",
        "        model = tf.keras.Model(inputs=[enc_inputs, dec_inputs], outputs=outputs)\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(optimizer=self.optimizer, loss=self.loss_function.compute, metrics=['accuracy'])\n",
        "\n",
        "        return model"
      ],
      "metadata": {
        "id": "8hskU2foJvxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrainer:\n",
        "    def __init__(self, model, dataset, validation_data, epochs):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.validation_data = validation_data\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def train(self):\n",
        "        # Prepare dataset for training by separating inputs and outputs\n",
        "        full_dataset = self.dataset.map(lambda enc_inputs, dec_inputs, dec_targets: ((enc_inputs, dec_inputs), dec_targets))\n",
        "\n",
        "        # Prepare validation dataset in a similar way\n",
        "        validation_dataset = self.validation_data.map(lambda enc_inputs, dec_inputs, dec_targets: ((enc_inputs, dec_inputs), dec_targets))\n",
        "\n",
        "        # Early stopping callback\n",
        "        early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(full_dataset, validation_data=validation_dataset, epochs=self.epochs,\n",
        "                       callbacks=[early_stopping_cb], verbose=1)\n",
        "        return history\n",
        "\n",
        "    def save_model(self, path):\n",
        "        self.model.save(path)\n"
      ],
      "metadata": {
        "id": "Sx4CFIZvm9Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel:\n",
        "    def __init__(self, preprocessing_config, model_config, epochs=5):\n",
        "        self.preprocessing_config = preprocessing_config\n",
        "        self.model_config = model_config\n",
        "        self.epochs = epochs\n",
        "        self.transformer = None\n",
        "        self.train_dataset = None\n",
        "        self.val_dataset = None\n",
        "        self.vocabulary_size = None\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "\n",
        "    def preprocess(self):\n",
        "        preprocessor = DataPreprocessor(self.preprocessing_config, verbose_1=True, verbose_2=True)\n",
        "        self.train_dataset, self.val_dataset, self.vocabulary_size, self.tokenizer = preprocessor.preprocess()\n",
        "        pe_input, pe_target = preprocessor.get_max_sequence_lengths()\n",
        "\n",
        "        self.model_config[\"pe_input\"] = pe_input\n",
        "        self.model_config[\"pe_target\"] = pe_target\n",
        "        self.model_config[\"input_vocab_size\"] = self.vocabulary_size\n",
        "        self.model_config[\"target_vocab_size\"] = self.vocabulary_size\n",
        "        print(\"Vocabulary size:\", self.vocabulary_size)\n",
        "\n",
        "    def create_model(self):\n",
        "        self.transformer = Transformer(**self.model_config)\n",
        "\n",
        "        loss_function = LossFunction()\n",
        "        learning_rate = CustomSchedule(self.model_config['d_model'])\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "        model_creator = ModelCreator(self.transformer, self.model_config, optimizer, loss_function)\n",
        "        self.model = model_creator.create_and_compile()\n",
        "\n",
        "    def summary(self):\n",
        "        self.model.summary()\n",
        "\n",
        "    def train(self):\n",
        "        model_trainer = ModelTrainer(self.model, self.train_dataset, self.val_dataset, self.epochs)\n",
        "        history = model_trainer.train()\n",
        "        return history, model_trainer\n",
        "\n",
        "    def save(self, model_trainer, path):\n",
        "        model_trainer.save_model(path)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.model.load_weights(path)\n",
        "\n",
        "    def print_layer_names(self):\n",
        "        for layer in self.model.layers:\n",
        "            print(layer.name)\n"
      ],
      "metadata": {
        "id": "Lsm96j-T9yyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurations\n",
        "preprocessing_config = {\n",
        "    'dataframe': df,\n",
        "    'column_name': 'text',\n",
        "    'data_proportion': 0.004,\n",
        "    'remove_list': ['\\n', '~', '[email protected]'],\n",
        "    'val_split_size': 0.2,\n",
        "    'max_sequence_len': 100,\n",
        "    'BATCH_SIZE': 32,\n",
        "    'BUFFER_SIZE': 2000,\n",
        "}\n",
        "\n",
        "\n",
        "model_config = {\n",
        "    \"enc_num_layers\": 4,\n",
        "    \"dec_num_layers\": 4,\n",
        "    \"d_model\": 256,  # Used for both encoder and decoder\n",
        "    \"enc_dff\": 512,\n",
        "    \"dec_dff\": 512,\n",
        "    \"enc_num_heads\": 4,\n",
        "    \"dec_num_heads\": 4,\n",
        "    \"pe_input\": 0,  # Will be updated after preprocessing\n",
        "    \"pe_target\": 0,  # Will be updated after preprocessing\n",
        "    \"input_vocab_size\": 0,  # Will be updated after preprocessing\n",
        "    \"target_vocab_size\": 0,  # Will be updated after preprocessing\n",
        "    \"enc_rate\": 0.1,\n",
        "    \"dec_rate\": 0.2,\n",
        "    \"verbose\": True\n",
        "}\n",
        "\n",
        "epochs = 2"
      ],
      "metadata": {
        "id": "aIw08qPvdDwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create TransformerModel instance\n",
        "transformer_model = TransformerModel(preprocessing_config, model_config, epochs)\n",
        "\n",
        "# Preprocess data\n",
        "transformer_model.preprocess()\n",
        "\n",
        "# Create model\n",
        "transformer_model.create_model()\n",
        "\n",
        "transformer_model.print_layer_names()\n",
        "\n",
        "# Train the model\n",
        "history, model_trainer = transformer_model.train()\n",
        "\n",
        "\n",
        "transformer_model.summary()"
      ],
      "metadata": {
        "id": "PsEK7ksX83Or",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79257448-215c-4dc6-e85a-7dff05c3bb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence Shapes:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Train Encoder Input Shape Train Decoder Input Shape  \\\n",
              "0                (626, 100)                (626, 100)   \n",
              "\n",
              "  Train Decoder Label Shape Val Encoder Input Shape Val Decoder Input Shape  \\\n",
              "0                (626, 100)              (157, 100)              (157, 100)   \n",
              "\n",
              "  Val Decoder Label Shape  \n",
              "0              (157, 100)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c65f8a2b-3fc7-41d5-b3b7-4cdc136ba9c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Encoder Input Shape</th>\n",
              "      <th>Train Decoder Input Shape</th>\n",
              "      <th>Train Decoder Label Shape</th>\n",
              "      <th>Val Encoder Input Shape</th>\n",
              "      <th>Val Decoder Input Shape</th>\n",
              "      <th>Val Decoder Label Shape</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(626, 100)</td>\n",
              "      <td>(626, 100)</td>\n",
              "      <td>(626, 100)</td>\n",
              "      <td>(157, 100)</td>\n",
              "      <td>(157, 100)</td>\n",
              "      <td>(157, 100)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c65f8a2b-3fc7-41d5-b3b7-4cdc136ba9c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c65f8a2b-3fc7-41d5-b3b7-4cdc136ba9c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c65f8a2b-3fc7-41d5-b3b7-4cdc136ba9c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Information:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               Dataset  Total Tokens  Total Parameters\n",
              "0  Train Encoder Input           626             62600\n",
              "1  Train Decoder Input           626             62600\n",
              "2  Train Decoder Label           626             62600\n",
              "3    Val Encoder Input           157             15700\n",
              "4    Val Decoder Input           157             15700\n",
              "5    Val Decoder Label           157             15700"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cd62159-ee72-4b7f-9ad0-0bb41a00fa9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Total Tokens</th>\n",
              "      <th>Total Parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train Encoder Input</td>\n",
              "      <td>626</td>\n",
              "      <td>62600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Train Decoder Input</td>\n",
              "      <td>626</td>\n",
              "      <td>62600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Train Decoder Label</td>\n",
              "      <td>626</td>\n",
              "      <td>62600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Val Encoder Input</td>\n",
              "      <td>157</td>\n",
              "      <td>15700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Val Decoder Input</td>\n",
              "      <td>157</td>\n",
              "      <td>15700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Val Decoder Label</td>\n",
              "      <td>157</td>\n",
              "      <td>15700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cd62159-ee72-4b7f-9ad0-0bb41a00fa9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5cd62159-ee72-4b7f-9ad0-0bb41a00fa9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5cd62159-ee72-4b7f-9ad0-0bb41a00fa9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 4017\n",
            "Encoder output shape: (None, None, 256)\n",
            "Decoder output shape: (None, None, 256)\n",
            "Final linear output shape: (None, None, 4017)\n",
            "decoder_input\n",
            "encoder_input\n",
            "decoder_lam_shape\n",
            "padding_mask_decoder\n",
            "padding_mask_encoder\n",
            "look_ahead_mask_ones_matrix\n",
            "padding_mask_expanded_decoder\n",
            "padding_mask_expanded_encoder\n",
            "look_ahead_mask\n",
            "Transformer_Block\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 54s 702ms/step - loss: 8.3599 - accuracy: 0.0000e+00 - val_loss: 8.3134 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 11s 533ms/step - loss: 8.2601 - accuracy: 0.0016 - val_loss: 8.1752 - val_accuracy: 0.0092\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_lam_shape (Lambda)     ()                   0           ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " padding_mask_decoder (Lambda)  (None, None)         0           ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " padding_mask_encoder (Lambda)  (None, None)         0           ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " look_ahead_mask_ones_matrix (L  (None, None)        0           ['decoder_lam_shape[0][0]']      \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " padding_mask_expanded_decoder   (None, 1, 1, None)  0           ['padding_mask_decoder[0][0]']   \n",
            " (Lambda)                                                                                         \n",
            "                                                                                                  \n",
            " padding_mask_expanded_encoder   (None, 1, 1, None)  0           ['padding_mask_encoder[0][0]']   \n",
            " (Lambda)                                                                                         \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, None)         0           ['look_ahead_mask_ones_matrix[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " Transformer_Block (Transformer  (None, None, 4017)  8360625     ['encoder_input[0][0]',          \n",
            " )                                                                'decoder_input[0][0]',          \n",
            "                                                                  'padding_mask_expanded_decoder[0\n",
            "                                                                 ][0]',                           \n",
            "                                                                  'padding_mask_expanded_encoder[0\n",
            "                                                                 ][0]',                           \n",
            "                                                                  'look_ahead_mask[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,360,625\n",
            "Trainable params: 8,360,625\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transformer_model.summary()"
      ],
      "metadata": {
        "id": "x_TYoIYm4NPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_layer_names(layer, prefix=\"\"):\n",
        "    print(prefix + layer.name)\n",
        "    try:\n",
        "        for sub_layer in layer.layers:\n",
        "            print_layer_names(sub_layer, prefix=prefix+\"----\")\n",
        "    except AttributeError:\n",
        "        # No further layers to inspect\n",
        "        pass\n",
        "\n",
        "print_layer_names(transformer_model.model)\n"
      ],
      "metadata": {
        "id": "7iTOJ2HnVD8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f4a61a-db47-4a31-adef-8d14d1b3a20c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "----decoder_input\n",
            "----encoder_input\n",
            "----decoder_lam_shape\n",
            "----padding_mask_decoder\n",
            "----padding_mask_encoder\n",
            "----look_ahead_mask_ones_matrix\n",
            "----padding_mask_expanded_decoder\n",
            "----padding_mask_expanded_encoder\n",
            "----look_ahead_mask\n",
            "----Transformer_Block\n",
            "--------Encoder\n",
            "--------Decoder\n",
            "--------transformer_final_layer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the model\n",
        "transformer_model.save(model_trainer, '/content/drive/MyDrive/Colab Notebooks/Machine Learning/TensorFlow/Transformer/Transformer_Weight/test_with_names_7')\n"
      ],
      "metadata": {
        "id": "jaBMvRyiM7ct",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "a31983fb-58ee-4682-e2d8-b6c925d8ea98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as encoder_embedding_layer_call_fn, encoder_embedding_layer_call_and_return_conditional_losses, encoder_encoding_layer_call_fn, encoder_encoding_layer_call_and_return_conditional_losses, dropout_8_layer_call_fn while saving (showing 5 of 268). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-9d486e1c57ee>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtransformer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/Machine Learning/TensorFlow/Transformer/Transformer_Weight/test_with_names_7'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-4d5b6f21b5d1>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, model_trainer, path)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-763065607464>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36mfill_object_graph_proto\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mchild_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mchild_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mchild_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmented_graph_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mchild_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: None has type NoneType, but expected one of: bytes, unicode"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n"
      ],
      "metadata": {
        "id": "iUwhJWbXC5yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h5f_names = h5py.File('/content/drive/MyDrive/Colab Notebooks/Machine Learning/TensorFlow/Transformer/Transformer_Weight/test_with_names_6.h5', 'r')\n",
        "# List all groups\n",
        "print(\"Keys: %s\" % h5f_names.keys())\n",
        "keys = list(h5f_names.keys())\n",
        "print(keys)\n",
        "\n",
        "# Get the data\n",
        "for key in keys:\n",
        "    print(\"\\nKey name: \", key)\n",
        "    data = list(h5f_names[key])\n",
        "    print(\"Data: \", data)"
      ],
      "metadata": {
        "id": "-yzA_pkAOYus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Transformer_Block = h5f_names['model_weights']\n",
        "\n",
        "for key in Transformer_Block.keys():\n",
        "    print(\"\\nKey name: \", key)\n",
        "    data = np.array(Transformer_Block[key])\n",
        "    print(\"Data shape: \", data.shape)\n",
        "    print(\"Data type: \", data.dtype)\n",
        "    print(\"First few elements: \", data.flat[:10])\n",
        "\n",
        "print(\"-----------------------------------------------------------------------------------\")\n",
        "\n",
        "Transformer_Block_Transformer_Block = h5f_names['model_weights/Transformer_Block']\n",
        "\n",
        "for key in Transformer_Block_Transformer_Block.keys():\n",
        "    print(\"\\nKey name: \", key)\n",
        "    data = np.array(Transformer_Block_Transformer_Block[key])\n",
        "    print(\"Data shape: \", data.shape)\n",
        "    print(\"Data type: \", data.dtype)\n",
        "    print(\"First few elements: \", data.flat[:10])\n",
        "\n",
        "\n",
        "print(\"-----------------------------------------------------------------------------------\")\n",
        "\n",
        "Transformer_Block_Variable_0 = h5f_names['model_weights/Transformer_Block/Transformer_Block/Encoder_Block']\n",
        "\n",
        "for key in Transformer_Block_Variable_0.keys():\n",
        "    print(\"\\nKey name: \", key)\n",
        "    data = np.array(Transformer_Block_Variable_0[key])\n",
        "    print(\"Data shape: \", data.shape)\n",
        "    print(\"Data type: \", data.dtype)\n",
        "    print(\"First few elements: \", data.flat[:10])"
      ],
      "metadata": {
        "id": "ZuKXwqprONg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4BW7XTx8X_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# h5f_no_names = h5py.File('/content/drive/MyDrive/Colab Notebooks/Machine Learning/TensorFlow/Transformer/Transformer_Weight/test6_no_name.h5', 'r')\n",
        "# # List all groups\n",
        "# print(\"Keys: %s\" % h5f_no_names.keys())\n",
        "# keys = list(h5f_no_names.keys())\n",
        "# print(keys)\n",
        "\n",
        "# # Get the data\n",
        "# for key in keys:\n",
        "#     print(\"\\nKey name: \", key)\n",
        "#     data = list(h5f_no_names[key])\n",
        "#     print(\"Data: \", data)"
      ],
      "metadata": {
        "id": "33ah2KvB8YIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer__no_names = h5f_no_names['transformer']\n",
        "\n",
        "# for key in Transformer__no_names.keys():\n",
        "#     print(\"\\nKey name: \", key)\n",
        "#     data = np.array(Transformer__no_names[key])\n",
        "#     print(\"Data shape: \", data.shape)\n",
        "#     print(\"Data type: \", data.dtype)\n",
        "#     print(\"First few elements: \", data.flat[:10])\n",
        "\n",
        "# print(\"-----------------------------------------------------------------------------------\")\n",
        "\n",
        "# Transformer__no_names_Transformer_Block = h5f_no_names['transformer/transformer']\n",
        "\n",
        "# for key in Transformer__no_names_Transformer_Block.keys():\n",
        "#     print(\"\\nKey name: \", key)\n",
        "#     data = np.array(Transformer__no_names_Transformer_Block[key])\n",
        "#     print(\"Data shape: \", data.shape)\n",
        "#     print(\"Data type: \", data.dtype)\n",
        "#     print(\"First few elements: \", data.flat[:10])\n",
        "\n",
        "\n",
        "# print(\"-----------------------------------------------------------------------------------\")\n",
        "\n",
        "# Transformer__no_names_Variable_0 = h5f_no_names['transformer/encoder']\n",
        "\n",
        "# for key in Transformer__no_names_Variable_0.keys():\n",
        "#     print(\"\\nKey name: \", key)\n",
        "#     data = np.array(Transformer__no_names_Variable_0[key])\n",
        "#     print(\"Data shape: \", data.shape)\n",
        "#     print(\"Data type: \", data.dtype)\n",
        "#     print(\"First few elements: \", data.flat[:10])"
      ],
      "metadata": {
        "id": "NV7pLLnp8YIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_layer_weights(layer):\n",
        "    \"\"\"Visualize weights of the provided layer.\"\"\"\n",
        "\n",
        "    # Get the weights of the specified layer\n",
        "    weights = layer.get_weights()\n",
        "\n",
        "    if len(weights) == 0:\n",
        "        print(f'Layer {layer.name} has no weights to visualize.')\n",
        "        return\n",
        "\n",
        "    # Create a figure\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Flatten the weights for visualization\n",
        "    weight_values = weights[0].flatten()  # 0 index for main weight matrix\n",
        "\n",
        "    # If weights are all zeros, print message and return\n",
        "    if np.all(weight_values == 0):\n",
        "        print(f'Weights for layer {layer.name} contain only zeros.')\n",
        "        return\n",
        "\n",
        "    # Plot histogram of weights\n",
        "    plt.hist(weight_values, bins=20)\n",
        "    plt.title('Layer ' + layer.name + ' Weight Distribution')\n",
        "    plt.xlabel('Weight values')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    # Compute statistics\n",
        "    weight_min = np.min(weight_values)\n",
        "    weight_max = np.max(weight_values)\n",
        "    weight_mean = np.mean(weight_values)\n",
        "    weight_std = np.std(weight_values)\n",
        "\n",
        "    # Annotate statistics\n",
        "    plt.annotate('Min: {:.2f}'.format(weight_min), xy=(0.05, 0.88), xycoords='axes fraction')\n",
        "    plt.annotate('Max: {:.2f}'.format(weight_max), xy=(0.05, 0.80), xycoords='axes fraction')\n",
        "    plt.annotate('Mean: {:.2f}'.format(weight_mean), xy=(0.05, 0.72), xycoords='axes fraction')\n",
        "    plt.annotate('Std: {:.2f}'.format(weight_std), xy=(0.05, 0.64), xycoords='axes fraction')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# model = transformer_model.model\n",
        "\n",
        "# visualize_layer_weights(model.layers[-1])"
      ],
      "metadata": {
        "id": "tm6vUAsJDZZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = transformer_model.model\n",
        "# tf.keras.utils.plot_model(\n",
        "#     model, to_file='model.png', show_shapes=True, show_dtype=True,\n",
        "#     show_layer_names=True, rankdir='TB', expand_nested=True, dpi=96\n",
        "# )\n"
      ],
      "metadata": {
        "id": "RE-yEgSeAEK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HistoryPlotter:\n",
        "    def __init__(self, history):\n",
        "        self.history = history\n",
        "\n",
        "    def plot_loss(self):\n",
        "        fig, ax = plt.subplots(figsize=(7, 5))\n",
        "        ax.plot(self.history.history['loss'], label='Training loss')\n",
        "        ax.plot(self.history.history['val_loss'], label='Validation loss')\n",
        "        ax.set_title('Model loss')\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.set_ylabel('Loss')\n",
        "        ax.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_accuracy(self):\n",
        "        fig, ax = plt.subplots(figsize=(7, 5))\n",
        "        ax.plot(self.history.history['accuracy'], label='Training accuracy')\n",
        "        ax.plot(self.history.history['val_accuracy'], label='Validation accuracy')\n",
        "        ax.set_title('Model accuracy')\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.set_ylabel('Accuracy')\n",
        "        ax.legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "MnghXYmatLtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot the training history\n",
        "# plotter = HistoryPlotter(history)\n",
        "\n",
        "# # Plot the loss\n",
        "# plotter.plot_loss()\n",
        "\n",
        "# # Plot the accuracy\n",
        "# plotter.plot_accuracy()"
      ],
      "metadata": {
        "id": "6jp3Ctf4-t4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model:"
      ],
      "metadata": {
        "id": "DWmQAOVoBnPh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ytmxubkfv_89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text generator"
      ],
      "metadata": {
        "id": "qkL7sFb-Jc0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class StochasticBeamSearch:\n",
        "    def __init__(self, model, tokenizer, beam_size=3):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.beam_size = beam_size\n",
        "\n",
        "    def decode_sequence(self, sequence):\n",
        "        index_to_word = dict((i, word) for word, i in self.tokenizer.word_index.items())\n",
        "        # Exclude the '<EOS>' token in the final output\n",
        "        return ' '.join(index_to_word.get(token, '?') for token in sequence if index_to_word.get(token, '?') != '<EOS>')\n",
        "\n",
        "    def predict(self, start_sentence, max_length=10):\n",
        "        start_tokens = self.tokenizer.texts_to_sequences([start_sentence])\n",
        "        start_tokens = np.squeeze(start_tokens, axis=0)\n",
        "\n",
        "        # Initialize beam with the start tokens\n",
        "        beam = [(start_tokens, 0.0)]  # each element in the beam is (token_sequence, log_probability)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            all_candidates = []\n",
        "\n",
        "            for tokens, log_prob in beam:\n",
        "                # Predict next tokens for all current sequences in the beam\n",
        "                tokens = np.expand_dims(tokens, axis=0)  # Make sure tokens have the shape [batch_size, seq_len]\n",
        "                predictions = self.model.predict([tokens, tokens], verbose=0)\n",
        "\n",
        "                # Select the last token from predictions\n",
        "                predictions = predictions[0, -1, :]\n",
        "\n",
        "                # Get top k tokens and probabilities\n",
        "                top_k_probs, top_k_tokens = tf.math.top_k(predictions, k=self.beam_size)\n",
        "\n",
        "                # Form next candidates by adding new tokens to current sequences\n",
        "                for k in range(self.beam_size):\n",
        "                    if tokens[0][-1] != top_k_tokens[k]:  # Add new token only if it's different from the last one\n",
        "                        updated_tokens = np.append(tokens, top_k_tokens[k])\n",
        "                        epsilon = 1e-9  # Small constant\n",
        "                        updated_log_prob = log_prob + np.log(top_k_probs[k].numpy() + epsilon)  # Convert tensor to numpy array before adding epsilon\n",
        "                        all_candidates.append((updated_tokens, updated_log_prob))\n",
        "\n",
        "            # Select new beam probabilistically\n",
        "            beam_probs = np.array([c[1] for c in all_candidates])\n",
        "            beam_probs = np.exp(beam_probs)  # Convert from log probabilities to probabilities\n",
        "\n",
        "            # Check for NaN values\n",
        "            if np.isnan(beam_probs).any():\n",
        "                print(\"NaN values detected in beam_probs. Replacing with uniform probabilities.\")\n",
        "                beam_probs = np.ones_like(beam_probs) / len(beam_probs)\n",
        "\n",
        "            # Make sure the probabilities sum up to 1\n",
        "            beam_probs = beam_probs / np.sum(beam_probs)\n",
        "            beam_indices = np.random.choice(range(len(beam_probs)), size=self.beam_size, p=beam_probs)\n",
        "\n",
        "            beam = [all_candidates[i] for i in beam_indices]\n",
        "\n",
        "            # Select the sequence with the highest probability from the final beam\n",
        "            tokens, _ = max(beam, key=lambda x: x[1])\n",
        "\n",
        "            # Check for EOS token and stop if found\n",
        "            if self.tokenizer.word_index['<EOS>'] in tokens:\n",
        "                break\n",
        "\n",
        "        # Decode tokens into text and return\n",
        "        return self.decode_sequence(tokens)\n"
      ],
      "metadata": {
        "id": "oQ8VkttMi9vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# beam_search = StochasticBeamSearch(transformer_model.model, transformer_model.tokenizer, beam_size=3)\n",
        "# text = beam_search.predict(\"the sun dipped below the horizon casting a \", 50)\n",
        "# print(text)\n"
      ],
      "metadata": {
        "id": "Z5-q2yMMjaTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R0EC56YPjbnW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}